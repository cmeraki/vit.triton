{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80966e24-909a-4e7c-914c-a496d4caa4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import ViTModel, ViTConfig\n",
    "\n",
    "from vit.vit import VIT\n",
    "from vit.utils import transfer_pretrained_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6daa88-e14c-437e-b0ff-7951a7d7affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def diff(a, b):\n",
    "    return torch.abs(a - b).mean()\n",
    "\n",
    "device = 'cuda:0'\n",
    "dtype = torch.float32\n",
    "model_id = 'google/vit-base-patch16-224'\n",
    "vit_config = ViTConfig(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f682a17-584b-4ef6-8cb8-2e94c3565777",
   "metadata": {},
   "source": [
    "**Loading weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fdd2b0-86a5-4862-9344-6eaa6e6e2559",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "height, width, channels = vit_config.image_size, vit_config.image_size, vit_config.num_channels\n",
    "patch_size = vit_config.patch_size\n",
    "hidden_dim = 768\n",
    "num_heads=vit_config.num_attention_heads\n",
    "num_layers=vit_config.num_hidden_layers\n",
    "\n",
    "model = VIT(\n",
    "    height=height,\n",
    "    width=width,\n",
    "    channels=channels,\n",
    "    patch_size=patch_size,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers\n",
    ")\n",
    "model.to(device, dtype)\n",
    "\n",
    "pretrained_model = ViTModel.from_pretrained(model_id, add_pooling_layer=False)\n",
    "pretrained_model.to(device, dtype)\n",
    "pretrained_model.eval()\n",
    "\n",
    "model = transfer_pretrained_weights(\n",
    "    pretrained_model=pretrained_model,\n",
    "    custom_model=model\n",
    ")\n",
    "\n",
    "sum(p.numel() for p in pretrained_model.parameters()), sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ce690b-e93e-4703-99f1-c7c609712ab0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfeab17-491b-41eb-9b0d-566e9fb5ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a277197-9233-442e-80f9-c61c3c0721d6",
   "metadata": {},
   "source": [
    "**Verifying layer by layer outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291b9fc0-0fab-408f-839f-70605b4aae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_pretrained = {}\n",
    "store_custom = {}\n",
    "\n",
    "def hook(module, input, output, name, store):\n",
    "    store[name] = output\n",
    "\n",
    "for name, layer in pretrained_model.named_modules():\n",
    "    layer.register_forward_hook(lambda layer, input, output, name=name: hook(layer, input, output, name, store_pretrained))\n",
    "\n",
    "for name, layer in model.named_modules():\n",
    "    layer.register_forward_hook(lambda layer, input, output, name=name: hook(layer, input, output, name, store_custom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b5d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn((1, 3, 224, 224)).to(device, dtype)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pretrained_out = pretrained_model(inputs)[0]\n",
    "    custom_out = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d32562-3280-4054-b530-ec527e1cff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_mapping = {\n",
    "    'embeddings.patch_embeddings.projection': 'embeddings.projection',\n",
    "    'embeddings.patch_embeddings': None,\n",
    "    'embeddings.dropout': None,\n",
    "    'embeddings': 'embeddings',\n",
    "    'layernorm': 'layernorm',\n",
    "}\n",
    "\n",
    "for i in range(0, num_heads):\n",
    "    weight_mapping.update({\n",
    "        f'encoder.layer.{i}.layernorm_before': f'encoder.layer.{i}.layernorm_before',\n",
    "        f'encoder.layer.{i}.attention.attention.query': [f'encoder.layer.{i}.attention.attention.0.query', f'encoder.layer.{i}.attention.attention.1.query', f'encoder.layer.{i}.attention.attention.2.query', f'encoder.layer.{i}.attention.attention.3.query', f'encoder.layer.{i}.attention.attention.4.query', f'encoder.layer.{i}.attention.attention.5.query', f'encoder.layer.{i}.attention.attention.6.query', f'encoder.layer.{i}.attention.attention.7.query', f'encoder.layer.{i}.attention.attention.8.query', f'encoder.layer.{i}.attention.attention.9.query', f'encoder.layer.{i}.attention.attention.10.query', f'encoder.layer.{i}.attention.attention.11.query'],\n",
    "        f'encoder.layer.{i}.attention.attention.key': [f'encoder.layer.{i}.attention.attention.0.key', f'encoder.layer.{i}.attention.attention.1.key', f'encoder.layer.{i}.attention.attention.2.key', f'encoder.layer.{i}.attention.attention.3.key', f'encoder.layer.{i}.attention.attention.4.key', f'encoder.layer.{i}.attention.attention.5.key', f'encoder.layer.{i}.attention.attention.6.key', f'encoder.layer.{i}.attention.attention.7.key', f'encoder.layer.{i}.attention.attention.8.key', f'encoder.layer.{i}.attention.attention.9.key', f'encoder.layer.{i}.attention.attention.10.key', f'encoder.layer.{i}.attention.attention.11.key'],\n",
    "        f'encoder.layer.{i}.attention.attention.value': [f'encoder.layer.{i}.attention.attention.0.value', f'encoder.layer.{i}.attention.attention.1.value', f'encoder.layer.{i}.attention.attention.2.value', f'encoder.layer.{i}.attention.attention.3.value', f'encoder.layer.{i}.attention.attention.4.value', f'encoder.layer.{i}.attention.attention.5.value', f'encoder.layer.{i}.attention.attention.6.value', f'encoder.layer.{i}.attention.attention.7.value', f'encoder.layer.{i}.attention.attention.8.value', f'encoder.layer.{i}.attention.attention.9.value', f'encoder.layer.{i}.attention.attention.10.value', f'encoder.layer.{i}.attention.attention.11.value'],\n",
    "        f'encoder.layer.{i}.attention.attention.dropout': None,\n",
    "        f'encoder.layer.{i}.attention.attention': [f'encoder.layer.{i}.attention.attention.0', f'encoder.layer.{i}.attention.attention.1', f'encoder.layer.{i}.attention.attention.2', f'encoder.layer.{i}.attention.attention.3', f'encoder.layer.{i}.attention.attention.4', f'encoder.layer.{i}.attention.attention.5', f'encoder.layer.{i}.attention.attention.6', f'encoder.layer.{i}.attention.attention.7', f'encoder.layer.{i}.attention.attention.8', f'encoder.layer.{i}.attention.attention.9', f'encoder.layer.{i}.attention.attention.10', f'encoder.layer.{i}.attention.attention.11'],\n",
    "        f'encoder.layer.{i}.attention.output.dense': None,\n",
    "        f'encoder.layer.{i}.attention.output.dropout': None,\n",
    "        f'encoder.layer.{i}.attention.output': f'encoder.layer.{i}.attention.output',\n",
    "        f'encoder.layer.{i}.attention': f'encoder.layer.{i}.attention',\n",
    "        f'encoder.layer.{i}.layernorm_after': f'encoder.layer.{i}.layernorm_after',\n",
    "        f'encoder.layer.{i}.intermediate.dense': f'encoder.layer.{i}.intermediate',\n",
    "        f'encoder.layer.{i}.intermediate.intermediate_act_fn': None,\n",
    "        f'encoder.layer.{i}.intermediate': None,\n",
    "        f'encoder.layer.{i}.output.dense': f'encoder.layer.{i}.output',\n",
    "        f'encoder.layer.{i}.output.dropout': None,\n",
    "        f'encoder.layer.{i}.output': None,\n",
    "        f'encoder.layer.{i}': f'encoder.layer.{i}',\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6953579-4f98-4218-a80f-410fb1ea2cef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k, v in weight_mapping.items():\n",
    "\n",
    "    if k and v:\n",
    "        if type(v) == list:\n",
    "            val2 = torch.cat([store_custom[e] for e in v], dim=-1)\n",
    "        else:\n",
    "            val2 = store_custom[v]\n",
    "\n",
    "        val1 = store_pretrained[k]\n",
    "\n",
    "        if type(val1) == tuple:\n",
    "            val1 = val1[0]\n",
    "\n",
    "        print(f'{k}\\t{val1.shape}, {v}\\t{val2.shape}\\t{torch.abs(val1-val2).max()}')\n",
    "\n",
    "        match = torch.allclose(val1, val2, rtol=0, atol=1)\n",
    "\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469fffda",
   "metadata": {},
   "source": [
    "Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9389157",
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = store_pretrained['encoder.layer.5.intermediate.dense']\n",
    "i2 = store_custom['encoder.layer.5.intermediate']\n",
    "\n",
    "w1 = pretrained_model.encoder.layer[5].output.dense.weight\n",
    "b1 = pretrained_model.encoder.layer[5].output.dense.bias\n",
    "\n",
    "w2 = model.encoder.layer[5].output.weight\n",
    "b2 = model.encoder.layer[5].output.bias\n",
    "\n",
    "z1 = torch.nn.functional.gelu(i1)\n",
    "\n",
    "# For i1, apply layernorm and then mult by \n",
    "\n",
    "v1 = store_pretrained['encoder.layer.5.output.dense']\n",
    "v2 = store_custom['encoder.layer.5.output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3870fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff(z1, i2), diff(w1.T, w2), diff(b1, b2), diff(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55ccc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "o1 = torch.matmul(z1, w1.T) + b1\n",
    "diff(v1, o1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e065ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit.kernels.matmul import matmul_triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75698dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = torch.ones_like(w2)\n",
    "b2 = torch.ones_like(b2)\n",
    "\n",
    "o2 = torch.matmul(i2, w2) + b2\n",
    "o2_hat = matmul_triton(i2, w2, b2)\n",
    "\n",
    "# diff(v2, o2), diff(v1, o2), diff(v2, o2_hat), diff(o2, o2_hat), diff(v1, o2_hat)\n",
    "\n",
    "diff(o2, o2_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a65f228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d1ed6e0-2425-4799-8fd6-ddd1519d3715",
   "metadata": {},
   "source": [
    "**Assigning identity weights for debugging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e66497-9f80-473c-a501-74ef2ceeaef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_state_dict = pretrained_model.state_dict()\n",
    "custom_state_dict = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d1bb05-e780-440f-9e26-7200958967b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_state_dict_new = {}\n",
    "custom_state_dict_new = {}\n",
    "\n",
    "for k, v in pretrained_state_dict.items():\n",
    "    pretrained_state_dict_new[k] = torch.ones_like(v).to(device, dtype)\n",
    "\n",
    "for k, v in custom_state_dict.items():\n",
    "    custom_state_dict_new[k] = torch.ones_like(v).to(device, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad789b6-2899-40e8-a475-b29e1b69cf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(custom_state_dict_new)\n",
    "pretrained_model.load_state_dict(pretrained_state_dict_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcd93ec-9933-4ef5-bd81-8bb2437942c5",
   "metadata": {},
   "source": [
    "**Benchmarking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7a4110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit.utils import benchmark\n",
    "\n",
    "batch_sizes = [1, 2, 4]\n",
    "hf_time, custom_time = benchmark(pretrained_model, model, batch_sizes=batch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aa102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(32, 3, 224, 224).to(device, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3ce837-91b2-417d-b154-b9b2234159f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pretrained_out = pretrained_model(inputs)[0]\n",
    "        custom_out = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fb7c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    m1_times = []\n",
    "    m2_times = []\n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "        pretrained_out = pretrained_model(inputs)[0]\n",
    "        m1_time = time.time() - start_time\n",
    "\n",
    "        start_time = time.time()\n",
    "        custom_out = model(inputs)\n",
    "        m2_time = time.time() - start_time\n",
    "\n",
    "        m1_times.append(m1_time)\n",
    "        m2_times.append(m2_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9534ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(m1_times), np.mean(m2_times)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
